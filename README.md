# ğŸŒ€ Solveur Lorentzien avec Cauchy Loss â€” IRLS Robust Optimizer

**Auteur : Thibaut LOMBARD**  
**Licence : MIT**

Ce dÃ©pÃ´t contient un solveur robuste basÃ© sur une approximation **quasi-lorentzienne** de la perte de Cauchy, implÃ©mentÃ© via un schÃ©ma **IRLS â€” Iteratively Reweighted Least Squares**.

Lâ€™objectif est de fournir une alternative robuste aux mÃ©thodes classiques (MSE, L-BFGS, Adam), capable de **rÃ©sister aux outliers** et dâ€™Ã©viter les minima dÃ©gÃ©nÃ©rÃ©s liÃ©s Ã  lâ€™hypothÃ¨se gaussienne des erreurs.

---

## ğŸš€ Pourquoi un solveur Â« Lorentzien Â» ?

La plupart des optimisations utilisent la perte quadratique :
```
L_MSE = âˆ‘ (y - fÎ¸(x))Â²
```
Elle explose en prÃ©sence dâ€™outliers.

La perte **de Cauchy**, issue dâ€™un modÃ¨le lorentzien, limite lâ€™influence des grandes erreurs :
```
L_Cauchy = âˆ‘ log(1 + rÂ² / ÏƒÂ²)
```
oÃ¹ `r = y âˆ’ fÎ¸(x)` et `Ïƒ` contrÃ´le lâ€™Ã©chelle des rÃ©sidus.

---

## ğŸ” Approche quasi-lorentzienne via IRLS

La perte de Cauchy nâ€™est pas quadratique â†’ difficile Ã  optimiser directement.

On lâ€™approxime localement par une perte quadratique **pondÃ©rÃ©e** :
```
log(1 + rÂ² / ÏƒÂ²) â‰ˆ w(r) Â· rÂ² + constante
```
avec le **poids Lorentzien** :
```
w(r) = 1 / (ÏƒÂ² + rÂ²)
```
â†’ Les points Ã©loignÃ©s (outliers) obtiennent un poids faible  
â†’ Les points fiables guident rÃ©ellement la descente

---

## ğŸ§® Algorithme IRLS

Pour des donnÃ©es `{(xi, yi)}` et un modÃ¨le `Å· = fÎ¸(x)` :

1. Initialiser les paramÃ¨tres `Î¸`
2. Fixer ou estimer `Ïƒ`
3. RÃ©pÃ©ter jusquâ€™Ã  convergence :
```
ri = yi - fÎ¸(xi) # rÃ©sidus
wi = 1 / (ÏƒÂ² + riÂ²) # poids Lorentziens
Minimiser âˆ‘ wi Â· (yi - fÎ¸(xi))Â²
Option : mettre Ã  jour Ïƒ via la mÃ©diane des rÃ©sidus
```
âœ” Chaque Ã©tape est un problÃ¨me convexe local  
âœ” Converge vers un minimum robuste de la perte Cauchy  
âœ” Identique Ã  ce qui est utilisÃ© dans Ceres Solver, GTSAM, OpenCV

---

## ğŸ Contenu du dÃ©pÃ´t
solver.py # implÃ©mentation IRLS + perte de Cauchy

Le script dâ€™exemple montre que la mÃ©thode :

- rÃ©siste aux outliers
- rÃ©cupÃ¨re des paramÃ¨tres fiables
- surpasse une rÃ©gression MSE simple

---

## ğŸ§  Avantages

| CritÃ¨re | Solveur Lorentzien |
|--------|-------------------|
| Sensible aux outliers | âŒ |
| Convergence stable | âœ”ï¸ |
| Compatible deep learning | âœ”ï¸ |
| InterprÃ©table (poids = confiance) | âœ”ï¸ |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/cauchy
python solver.py
```
